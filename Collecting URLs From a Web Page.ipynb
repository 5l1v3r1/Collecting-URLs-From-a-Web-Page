{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting URLs From a Web Page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this script, we want to find and collect URLs from a target web page. Many web pages not only include full URLs but also they include tags also. So, while scrapt the URLs it doesn't be ignored this details.\n",
    "\n",
    "In this script, we both collect full URLs and tags from the target web page. Then, start to find and collect new URLs from web pages which we reach from target web pages. Namely, we continue to collect URLs in a loop. Also we note down if a web page doesn't include any URL and continue the other URL.\n",
    "\n",
    "While this study. we prefer to save the URLs in a dataframe instead of list or something else. And finally we save the result in a CSV file.\n",
    "\n",
    "We use;\n",
    "- pandas\n",
    "- urllib\n",
    "- BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 http://python-data.dr-chuck.net/ >>URL>> http://www.py4e.com/\n",
      "2 http://python-data.dr-chuck.net/ >>URL>> http://www.twitter.com/drchuck\n",
      "3 http://python-data.dr-chuck.net/ >>URL>> http://www.dr-chuck.com/\n",
      "4 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/geojson\n",
      "5 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/regex_sum_42.txt\n",
      "6 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/comments_42.html\n",
      "7 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/comments_42.xml\n",
      "8 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/comments_42.json\n",
      "9 http://python-data.dr-chuck.net/ >>tag>> http://python-data.dr-chuck.net/known_by_42.html\n",
      "10 http://python-data.dr-chuck.net/ >>URL>> https://www.cloudflare.com/\n",
      "11 http://python-data.dr-chuck.net/ >>URL>> http://py4e-data.dr-chuck.net\n",
      ">> http://www.py4e.com/\n",
      "In http://www.py4e.com/ there is no link!!!\n",
      ">> http://www.dr-chuck.com/\n",
      "12 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/csev-blog/\n",
      "13 http://www.dr-chuck.com/ >>URL>> https://www.si.umich.edu/\n",
      "14 http://www.dr-chuck.com/ >>URL>> https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\n",
      "15 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/csev-blog/\n",
      "16 http://www.dr-chuck.com/ >>URL>> https://www.twitter.com/drchuck/\n",
      "17 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/dr-chuck/resume/speaking.htm\n",
      "18 http://www.dr-chuck.com/ >>URL>> https://www.slideshare.net/csev\n",
      "19 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//dr-chuck/resume/index.htm\n",
      "20 http://www.dr-chuck.com/ >>URL>> https://amzn.to/1K5Q81K\n",
      "21 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/instructor/drchuck\n",
      "22 http://www.dr-chuck.com/ >>URL>> http://afs.dr-chuck.com/papers/\n",
      "23 http://www.dr-chuck.com/ >>URL>> https://itunes.apple.com/us/podcast/computing-conversations/id731495760\n",
      "24 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "25 http://www.dr-chuck.com/ >>URL>> https://developers.imsglobal.org/\n",
      "26 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/user/csev\n",
      "27 http://www.dr-chuck.com/ >>URL>> https://vimeo.com/drchuck/videos\n",
      "28 http://www.dr-chuck.com/ >>URL>> https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\n",
      "29 http://www.dr-chuck.com/ >>URL>> https://www.linkedin.com/in/charlesseverance/\n",
      "30 http://www.dr-chuck.com/ >>URL>> https://www.researchgate.net/profile/Charles_Severance/\n",
      "31 http://www.dr-chuck.com/ >>URL>> https://www.tsugicloud.org/\n",
      "32 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//office\n",
      "33 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/course/learn/python\n",
      "34 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/specializations/web-applications/\n",
      "35 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/course/insidetheinternet\n",
      "36 http://www.dr-chuck.com/ >>URL>> http://www.py4e.com\n",
      "37 http://www.dr-chuck.com/ >>URL>> http://www.wa4e.com/\n",
      "38 http://www.dr-chuck.com/ >>URL>> http://www.dj4e.com/\n",
      "39 http://www.dr-chuck.com/ >>URL>> http://www.py4e.com/book\n",
      "40 http://www.dr-chuck.com/ >>URL>> http://www.pythonlearn.com/\n",
      "41 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//sakai-book\n",
      "42 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20\n",
      "43 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20\n",
      "44 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\n",
      "45 http://www.dr-chuck.com/ >>URL>> http://oreilly.com/catalog/9781565923126/\n",
      "46 http://www.dr-chuck.com/ >>URL>> http://cnx.org/content/col11136/latest/\n",
      "47 http://www.dr-chuck.com/ >>URL>> https://www.sakaiproject.org/\n",
      "48 http://www.dr-chuck.com/ >>URL>> https://www.tsugi.org/\n",
      "49 http://www.dr-chuck.com/ >>URL>> https://developers.imsglobal.org/\n",
      "50 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//obi-sample\n",
      "51 http://www.dr-chuck.com/ >>URL>> http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "52 http://www.dr-chuck.com/ >>URL>> https://www.vimeo.com/17207620\n",
      "53 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=BVKpW02hsrU\n",
      "54 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=sa2WsgCvn7c\n",
      "55 http://www.dr-chuck.com/ >>URL>> https://www.vimeo.com/17213019\n",
      "56 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=FJ078sO35M0\n",
      "57 http://www.dr-chuck.com/ >>URL>> http://afs.dr-chuck.com/citoolkit\n",
      "58 http://www.dr-chuck.com/ >>URL>> https://twitter.com/drchuck\n",
      ">> http://www.dr-chuck.com/\n",
      "59 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/csev-blog/\n",
      "60 http://www.dr-chuck.com/ >>URL>> https://www.si.umich.edu/\n",
      "61 http://www.dr-chuck.com/ >>URL>> https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1159280\n",
      "62 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/csev-blog/\n",
      "63 http://www.dr-chuck.com/ >>URL>> https://www.twitter.com/drchuck/\n",
      "64 http://www.dr-chuck.com/ >>URL>> https://www.dr-chuck.com/dr-chuck/resume/speaking.htm\n",
      "65 http://www.dr-chuck.com/ >>URL>> https://www.slideshare.net/csev\n",
      "66 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//dr-chuck/resume/index.htm\n",
      "67 http://www.dr-chuck.com/ >>URL>> https://amzn.to/1K5Q81K\n",
      "68 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/instructor/drchuck\n",
      "69 http://www.dr-chuck.com/ >>URL>> http://afs.dr-chuck.com/papers/\n",
      "70 http://www.dr-chuck.com/ >>URL>> https://itunes.apple.com/us/podcast/computing-conversations/id731495760\n",
      "71 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "72 http://www.dr-chuck.com/ >>URL>> https://developers.imsglobal.org/\n",
      "73 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/user/csev\n",
      "74 http://www.dr-chuck.com/ >>URL>> https://vimeo.com/drchuck/videos\n",
      "75 http://www.dr-chuck.com/ >>URL>> https://backpack.openbadges.org/share/4f76699ddb399d162a00b89a452074b3/\n",
      "76 http://www.dr-chuck.com/ >>URL>> https://www.linkedin.com/in/charlesseverance/\n",
      "77 http://www.dr-chuck.com/ >>URL>> https://www.researchgate.net/profile/Charles_Severance/\n",
      "78 http://www.dr-chuck.com/ >>URL>> https://www.tsugicloud.org/\n",
      "79 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//office\n",
      "80 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/course/learn/python\n",
      "81 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/specializations/web-applications/\n",
      "82 http://www.dr-chuck.com/ >>URL>> https://www.coursera.org/course/insidetheinternet\n",
      "83 http://www.dr-chuck.com/ >>URL>> http://www.py4e.com\n",
      "84 http://www.dr-chuck.com/ >>URL>> http://www.wa4e.com/\n",
      "85 http://www.dr-chuck.com/ >>URL>> http://www.dj4e.com/\n",
      "86 http://www.dr-chuck.com/ >>URL>> http://www.py4e.com/book\n",
      "87 http://www.dr-chuck.com/ >>URL>> http://www.pythonlearn.com/\n",
      "88 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//sakai-book\n",
      "89 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/gp/product/1624311393/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=1624311393&linkCode=as2&tag=drchu02-20\n",
      "90 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/gp/product/059680069X/ref=as_li_ss_tl?ie=UTF8&camp=1789&creative=390957&creativeASIN=059680069X&linkCode=as2&tag=drchu02-20\n",
      "91 http://www.dr-chuck.com/ >>URL>> http://www.amazon.com/Performance-Computing-Architectures-Optimization-Benchmarks/dp/156592312X/\n",
      "92 http://www.dr-chuck.com/ >>URL>> http://oreilly.com/catalog/9781565923126/\n",
      "93 http://www.dr-chuck.com/ >>URL>> http://cnx.org/content/col11136/latest/\n",
      "94 http://www.dr-chuck.com/ >>URL>> https://www.sakaiproject.org/\n",
      "95 http://www.dr-chuck.com/ >>URL>> https://www.tsugi.org/\n",
      "96 http://www.dr-chuck.com/ >>URL>> https://developers.imsglobal.org/\n",
      "97 http://www.dr-chuck.com/ >>tag>> http://www.dr-chuck.com//obi-sample\n",
      "98 http://www.dr-chuck.com/ >>URL>> http://www.youtube.com/playlist?list=PLHJB2bhmgB7dFuY7HmrXLj5BmHGKTD-3R\n",
      "99 http://www.dr-chuck.com/ >>URL>> https://www.vimeo.com/17207620\n",
      "100 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=BVKpW02hsrU\n",
      "101 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=sa2WsgCvn7c\n",
      "102 http://www.dr-chuck.com/ >>URL>> https://www.vimeo.com/17213019\n",
      "103 http://www.dr-chuck.com/ >>URL>> https://www.youtube.com/watch?v=FJ078sO35M0\n",
      "104 http://www.dr-chuck.com/ >>URL>> http://afs.dr-chuck.com/citoolkit\n",
      "105 http://www.dr-chuck.com/ >>URL>> https://twitter.com/drchuck\n",
      ">> http://python-data.dr-chuck.net/geojson\n",
      "OK, the limit (100 URL) surpassed, totally 105 URL scraped\n"
     ]
    }
   ],
   "source": [
    "#find links and add to dataframe\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "n=0\n",
    "m=0\n",
    "url='http://python-data.dr-chuck.net/'\n",
    "df_url=pd.DataFrame()\n",
    "df_url_tot=pd.DataFrame()\n",
    "\n",
    "while n<100:\n",
    "    try:\n",
    "        html_page = urlopen(url)     \n",
    "        soup = BeautifulSoup(html_page)\n",
    "        for link in soup.findAll('a'):\n",
    "            n+=1\n",
    "            tag=link.get('href')\n",
    "            if 'http' in tag:\n",
    "                new_url=link.get('href')\n",
    "                df_url['Count'], df_url[\"Source\"],df_url[\"Destination\"] = [[n], [url],[new_url]]\n",
    "                print(n, url,'>>URL>>',new_url)\n",
    "                df_url_tot=df_url_tot.append(df_url)\n",
    "            else:\n",
    "                new_url=url+tag\n",
    "                print(n, url,'>>tag>>',new_url)\n",
    "                df_url['Count'], df_url[\"Source\"],df_url[\"Destination\"] = [[n], [url],[new_url]]\n",
    "                df_url_tot=df_url_tot.append(df_url)\n",
    "        df_url_tot=df_url_tot.reset_index(drop=True)\n",
    "        url=df_url_tot.loc[m,\"Destination\"]\n",
    "        print('>>',url)\n",
    "        m+=1\n",
    "    except:\n",
    "        print('In {} there is no link!!!'.format(url))\n",
    "        m+=1\n",
    "        url=df_url_tot.loc[m,\"Destination\"]\n",
    "        print('>>',url)\n",
    "else:\n",
    "    print('OK, the limit (100 URL) surpassed, totally {} URL scraped'.format(n))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Count</th>\n",
       "      <th>Source</th>\n",
       "      <th>Destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>http://python-data.dr-chuck.net/</td>\n",
       "      <td>http://www.py4e.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>http://python-data.dr-chuck.net/</td>\n",
       "      <td>http://www.twitter.com/drchuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>http://python-data.dr-chuck.net/</td>\n",
       "      <td>http://www.dr-chuck.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>http://python-data.dr-chuck.net/</td>\n",
       "      <td>http://python-data.dr-chuck.net/geojson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>http://python-data.dr-chuck.net/</td>\n",
       "      <td>http://python-data.dr-chuck.net/regex_sum_42.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Count                            Source  \\\n",
       "0      1  http://python-data.dr-chuck.net/   \n",
       "1      2  http://python-data.dr-chuck.net/   \n",
       "2      3  http://python-data.dr-chuck.net/   \n",
       "3      4  http://python-data.dr-chuck.net/   \n",
       "4      5  http://python-data.dr-chuck.net/   \n",
       "\n",
       "                                        Destination  \n",
       "0                              http://www.py4e.com/  \n",
       "1                    http://www.twitter.com/drchuck  \n",
       "2                          http://www.dr-chuck.com/  \n",
       "3           http://python-data.dr-chuck.net/geojson  \n",
       "4  http://python-data.dr-chuck.net/regex_sum_42.txt  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_url_tot=df_url_tot.reset_index(drop=True)\n",
    "df_url_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved!\n"
     ]
    }
   ],
   "source": [
    "#Save to CSV file\n",
    "df_url_tot.to_csv('URLs.csv')\n",
    "print('Saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
